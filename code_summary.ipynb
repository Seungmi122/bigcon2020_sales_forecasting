{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE SUMMARY (ㅁㅁㅁㅉ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# model\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "TARGET = '취급액'\n",
    "\n",
    "# directories\n",
    "LOCAL_DIR = \"..\"\n",
    "MODELS_DIR = LOCAL_DIR + \"/data/saved_models/\"\n",
    "PROCESSED_DATA_DIR = LOCAL_DIR + \"/data/20/\"\n",
    "FEATURED_DATA_DIR = LOCAL_DIR + '/data/20/'\n",
    "SUBMISSION_DIR = LOCAL_DIR + \"/submission/\"\n",
    "OPT_DATA_DIR = LOCAL_DIR + \"/data/13/\"\n",
    "RAW_DATA_DIR = LOCAL_DIR + \"/data/00/\"\n",
    "\n",
    "# set global vars\n",
    "data_list = ['df_wk_lag', 'df_wk_no_lag', 'df_wd_lag', 'df_wd_no_lag', 'df_all_lag']\n",
    "\n",
    "lag_col1 = ['lag_scode_price', 'lag_scode_count', 'lag_mcode_price', 'lag_mcode_count', 'lag_bigcat_price',\n",
    "            'lag_bigcat_count', 'lag_bigcat_price_day', 'lag_bigcat_count_day', 'lag_small_c_price',\n",
    "            'lag_small_c_count', 'lag_all_price_show', 'lag_all_price_day']\n",
    "\n",
    "lag_col2 = ['ts_pred', 'rolling_mean_7', 'rolling_mean_14', 'rolling_mean_21',\n",
    "            'rolling_mean_28', 'mean_sales_origin']\n",
    "\n",
    "lag_wd = ['lag_sales_wd_1', 'lag_sales_wd_2', 'lag_sales_wd_3','lag_sales_wd_4', 'lag_sales_wd_5']\n",
    "lag_wk = ['lag_sales_wk_1', 'lag_sales_wk_2']\n",
    "full_lag_col = ['lag_sales_1', 'lag_sales_2', 'lag_sales_5', 'lag_sales_7']\n",
    "\n",
    "cat_col = ['상품군', 'weekdays', 'show_id', 'small_c', 'middle_c', 'big_c',\n",
    "           'pay', 'months', 'hours_inweek', 'weekends', 'japp', 'parttime',\n",
    "           'min_start', 'primetime', 'prime_smallc',\n",
    "           'freq', 'bpower', 'steady', 'men', 'pay', 'luxury',\n",
    "           'spring', 'summer', 'fall', 'winter', 'rain']\n",
    "\n",
    "encoded_cols = ['상품코드', '상품군', 'weekdays', 'parttime', 'show_id','small_c', 'middle_c',\n",
    "                'big_c', 'original_c', 'pay', 'exposed_t']\n",
    "\n",
    "base_cols = ['방송일시', '노출(분)', '마더코드', '상품코드', '상품명', '상품군', '판매단가', '취급액']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    \"\"\"\n",
    "    :objective: load data\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_pickle(path)\n",
    "        return df.reset_index()\n",
    "    except:\n",
    "        print(\"check file directory\")\n",
    "\n",
    "\n",
    "def drop_useless(df):\n",
    "    \"\"\"\n",
    "    :objective: drop useless features for model.\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    #useless features\n",
    "    xcol = ['방송일시', '노출(분)', '마더코드', '상품명', 'exposed', 'ymd', 'volume',\n",
    "            'years', 'days', 'hours', 'week_num', 'holidays', 'red', 'min_range', 'brand',\n",
    "            'small_c_code', 'middle_c_code', 'big_c_code', 'sales_power']\n",
    "    col = [x for x in df.columns if x in xcol]\n",
    "    df = df.drop(columns=col)\n",
    "    df = df.copy()\n",
    "    return df\n",
    "\n",
    "def check_na(df):\n",
    "    \"\"\"\n",
    "    :objective: show na\n",
    "    :return: columns with na / na counts\n",
    "    \"\"\"\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "def na_to_zeroes(df):\n",
    "    \"\"\"\n",
    "    :objective: Change all na's to zero.(just for original lag!)\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    xcol = [x for x in df.columns if\n",
    "            x in lag_col1 + lag_col2 + ['mid_click_r', 'age30_middle', 'age40_middle', 'age50_middle',\n",
    "                                        'age60above_middle', 'pc_middle', 'mobile_middle']]\n",
    "    for col in xcol:\n",
    "        df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "def run_label_all(df):\n",
    "    \"\"\"\n",
    "    :objective: Perform labelencoding for all categorical/object columns\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    lab_col = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "    for col in lab_col:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].values)\n",
    "    return df\n",
    "\n",
    "def run_preprocess(df):\n",
    "    \"\"\"\n",
    "    :objective: Run Feature deletion, NA imputation, label encoding\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    df = drop_useless(df)\n",
    "    df = na_to_zeroes(df)\n",
    "    df = run_label_all(df)\n",
    "    df1 = df.copy()\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeder\n",
    "def seed_everything(seed=127):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# metrics\n",
    "# negative mape (For Bayesian Optimization)\n",
    "def neg_mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    result = (-1) * mape\n",
    "    return result\n",
    "\n",
    "# MAPE\n",
    "def get_mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    final = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return final\n",
    "\n",
    "# RMSE\n",
    "def get_rmse(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    return rmse\n",
    "\n",
    "# MAE\n",
    "def get_mae(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def cv_split(df, month, printprop=False):\n",
    "    \"\"\"\n",
    "    :objective: get index to create cross validation dataset\n",
    "    :param df: pandas dataframe\n",
    "    :param month: int - from 1 to 12, month to be splited\n",
    "    :param printprop: boolean - whether to print proportion of cv to full data\n",
    "    :return: int - index for full data to be splited\n",
    "    \"\"\"\n",
    "    split = int(df[df['months'] == month].index.values.max())\n",
    "    prop = str(split / df.shape[0])\n",
    "    if printprop:\n",
    "        print(f'Proportion of train set is {prop}')\n",
    "        return split\n",
    "    else:\n",
    "        return split\n",
    "\n",
    "\n",
    "def divide_train_val(df_pp, month, drop):\n",
    "    \"\"\"\n",
    "    :objective: divide full data into train, validation\n",
    "    :param df_pp: pandas dataframe, preprocessed\n",
    "    :param month: int - from 1 to 12, month to be splited\n",
    "    :param drop: list of str - columns to be dropped\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    split = cv_split(df=df_pp, month=month)\n",
    "    train_x = df_pp.iloc[:split, :].drop(columns=['index',\n",
    "                                                  'show_id', TARGET] + drop)  ## 'index' check!!\n",
    "    train_y = df_pp.iloc[:split, :][TARGET]\n",
    "    val_x = df_pp.iloc[split:, :].drop(columns=['index',\n",
    "                                                'show_id', TARGET] + drop)\n",
    "    val_y = df_pp.iloc[split:, :][TARGET]\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "\n",
    "def divide_top(df, num_train, num_val):\n",
    "    \"\"\"\n",
    "    :objective: divide full data by mean_sales_origin ranking\n",
    "    :param df: pandas dataframe\n",
    "    :param num_train: int - index to divide train and val\n",
    "    :param num_val: int - index to divide train and val\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    top_df = df.sort_values('mean_sales_origin', ascending=False)\n",
    "\n",
    "    top_tr_lag_x = top_df.iloc[:num_train, :].drop(['index', 'show_id', TARGET], axis=1)\n",
    "    top_tr_lag_y = top_df.iloc[:num_train, :][TARGET]\n",
    "    top_v_lag_x = top_df.iloc[num_train:(num_train + num_val), :].drop(['index', 'show_id', TARGET], axis=1)\n",
    "    top_v_lag_y = top_df.iloc[num_train:(num_train + num_val), :][TARGET]\n",
    "\n",
    "    return top_df, top_tr_lag_x, top_tr_lag_y, top_v_lag_x, top_v_lag_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 4 types of dataset\n",
    "# Descriptions:\n",
    "#   - df_wd_lag : weekday / + lags\n",
    "#   - df_wk_lag: weekend / + lags\n",
    "#   - df_wd_test : weekday / + lags on test data\n",
    "#   - df_wk_test: weekend / + lags on test data\n",
    "\n",
    "df_wd_lag = load_df(FEATURED_DATA_DIR + '/train_fin_wd_lag.pkl')\n",
    "df_wk_lag = load_df(FEATURED_DATA_DIR + '/train_fin_wk_lag.pkl')\n",
    "\n",
    "df_wd_test = load_df(FEATURED_DATA_DIR + '/test_fin_wd_lag.pkl')\n",
    "df_wk_test = load_df(FEATURED_DATA_DIR + '/test_fin_wk_lag.pkl')\n",
    "\n",
    "# combined data for label encoding\n",
    "tmp_combined = pd.concat([df_wd_lag, df_wk_lag, df_wd_test, df_wk_test]).drop(columns=['index'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessed datasets\n",
    "tmp_combined = run_preprocess(tmp_combined)\n",
    "df_wd_lag_PP = tmp_combined.loc[:, tmp_combined.columns.isin(df_wd_lag.columns)].iloc[:df_wd_lag.shape[0]].reset_index()\n",
    "df_wk_lag_PP = tmp_combined.loc[:, tmp_combined.columns.isin(df_wk_lag.columns)]\\\n",
    "                .iloc[df_wd_lag.shape[0]:(df_wd_lag.shape[0]+df_wk_lag.shape[0])].reset_index()\n",
    "df_wd_test_PP = tmp_combined.loc[:, tmp_combined.columns.isin(df_wd_test.columns)]\\\n",
    "                .iloc[(df_wd_lag.shape[0]+df_wk_lag.shape[0]):(df_wd_lag.shape[0]+df_wk_lag.shape[0]+df_wd_test.shape[0])]\n",
    "df_wk_test_PP = tmp_combined.loc[:, tmp_combined.columns.isin(df_wk_test.columns)].iloc[-df_wk_test.shape[0]:]\n",
    "\n",
    "# write pickle for test data\n",
    "df_wd_test_PP.to_pickle(FEATURED_DATA_DIR + 'test_fin_wd_PP.pkl')\n",
    "df_wk_test_PP.to_pickle(FEATURED_DATA_DIR + 'test_fin_wk_PP.pkl')\n",
    "# Divide data\n",
    "# WD\n",
    "train_wd_lag_x, train_wd_lag_y, val_wd_lag_x, val_wd_lag_y = divide_train_val(df_wd_lag_PP, 8, drop=[])\n",
    "top_wd_lag, top_tr_wd_lag_x, top_tr_wd_lag_y, top_v_wd_lag_x, top_v_wd_lag_y = divide_top(df_wd_lag_PP, 4004, 2013)\n",
    "# WK\n",
    "train_wk_lag_x, train_wk_lag_y, val_wk_lag_x, val_wk_lag_y = divide_train_val(df_wk_lag_PP, 8, drop=[])\n",
    "top_wk_lag, top_tr_wk_lag_x, top_tr_wk_lag_y, top_v_wk_lag_x, top_v_wk_lag_y = divide_top(df_wk_lag_PP, 2206, 999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lgbm(params, train_x, train_y, val_x, val_y, df_type='wd_all'):\n",
    "    \"\"\"\n",
    "    :objective: run lgbm model\n",
    "    :param params: dictionary\n",
    "    :param train_x: pd.DataFrame\n",
    "    :param train_y: pd.DataFrame\n",
    "    :param val_x: pd.DataFrame\n",
    "    :param val_y: pd.DataFrame\n",
    "    :param df_type: str - 'wd_all', 'wk_all', 'wd_top', 'wk_top'\n",
    "    :return: LGBMRegressor, np.array\n",
    "    \"\"\"\n",
    "\n",
    "    seed_everything(seed=127)\n",
    "\n",
    "    model_lg = LGBMRegressor(**params)\n",
    "    model_lg.fit(train_x, train_y)\n",
    "    lgbm_preds = model_lg.predict(val_x)\n",
    "\n",
    "    # Plot LGBM: Predicted vs. True values\n",
    "    plt.figure(figsize= (40,5))\n",
    "    plt.rcParams[\"axes.grid.axis\"] = \"y\"\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    x = range(0, len(lgbm_preds))\n",
    "    plt.plot(x, val_y, label='true', marker='', color='grey', linewidth=2, alpha=0.8)\n",
    "    plt.plot(x, lgbm_preds, label='predicted', marker='', color='tomato', linewidth=2)\n",
    "    pop_b = mpatches.Patch(color='tomato', label='Predicted')\n",
    "    pop_c = mpatches.Patch(color='grey', label='True')\n",
    "    plt.legend(handles=[pop_b, pop_c], fontsize=27, loc=2)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xlabel('Time', fontsize=25)\n",
    "    plt.ylabel('Sales', fontsize=25)\n",
    "    plt.show()\n",
    "\n",
    "    # Get Scores\n",
    "    print(f'MAPE of best iter is {get_mape(val_y, lgbm_preds)}')\n",
    "    print(f'MAE of best iter is {get_mae(val_y, lgbm_preds)}')\n",
    "\n",
    "    model_name = MODELS_DIR + 'lgbm_finalmodel_' + df_type + '.bin'\n",
    "    pickle.dump(model_lg, open(model_name, 'wb'))\n",
    "\n",
    "    return model_lg, lgbm_preds\n",
    "\n",
    "##################################################################\n",
    "################# Step 1. For ALL observations ###################\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# parameters for wd/wk model\n",
    "params_all_wd = {'feature_fraction': 1,\n",
    "                 'learning_rate': 0.001,\n",
    "                 'min_data_in_leaf': 135,\n",
    "                 'n_estimators': 3527,\n",
    "                 'num_iterations': 2940,\n",
    "                 'subsample': 1,\n",
    "                 'boosting_type': 'dart',\n",
    "                 'objective': 'regression',\n",
    "                 'metric': 'mape',\n",
    "                 'categorical_feature': [3, 9, 10, 11]  ## weekdays, small_c, middle_c, big_c\n",
    "                 }\n",
    "\n",
    "params_all_wk = {'feature_fraction': 1,\n",
    "                 'learning_rate': 0.001,\n",
    "                 'min_data_in_leaf': 134,\n",
    "                 'n_estimators': 3474,\n",
    "                 'num_iterations': 2928,\n",
    "                 'subsample': 1,\n",
    "                 'boosting_type': 'dart',\n",
    "                 'objective': 'regression',\n",
    "                 'metric': 'mape',\n",
    "                 'categorical_feature': [3, 9, 10, 11]}  ## weekdays, small_c, middle_c, big_c\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "################### Step 2. For High-rank observations ###################\n",
    "###########################################################################\n",
    "\n",
    "params_top_wd = {'feature_fraction': 1,\n",
    "                 'learning_rate': 0.0025,\n",
    "                 'min_data_in_leaf': 70,\n",
    "                 'n_estimators': 5000,\n",
    "                 'num_iterations': 4000,\n",
    "                 'subsample': 1,\n",
    "                 'boosting_type': 'dart',\n",
    "                 'objective': 'regression',\n",
    "                 'metric': 'mape',\n",
    "                 'categorical_feature': [3, 9, 10, 11]  ## weekdays, small_c, middle_c, big_c\n",
    "                 }\n",
    "\n",
    "params_top_wk = {'feature_fraction': 1,\n",
    "                 'learning_rate': 0.0025,\n",
    "                 'min_data_in_leaf': 30,\n",
    "                 'n_estimators': 5000,\n",
    "                 'num_iterations': 3500,\n",
    "                 'subsample': 1,\n",
    "                 'boosting_type': 'dart',\n",
    "                 'objective': 'regression',\n",
    "                 'metric': 'mape',\n",
    "                 'categorical_feature': [3, 9, 10, 11]  ## weekdays, small_c, middle_c, big_c\n",
    "                 }\n",
    "\n",
    "#####################################################################\n",
    "############## Step 3. Mix results from step1 & step2 ###############\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "def mixed_df(model_top, top_df, val_all_df_x, preds_all, num_top):\n",
    "    \"\"\"\n",
    "    :objective:\n",
    "    :param model_top:\n",
    "    :param top_df:\n",
    "    :param val_all_df_x:\n",
    "    :param preds_all:\n",
    "    :param num_top:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    top_idx = set(top_df.iloc[:num_top, :].index)\n",
    "    val_idx = set(val_all_df_x.index)\n",
    "    top_in_val = list(val_idx.intersection(top_idx))\n",
    "\n",
    "    val_copy = val_all_df_x.copy()\n",
    "    val_copy[TARGET] = preds_all\n",
    "\n",
    "    for i in top_in_val:\n",
    "        val_copy[TARGET].loc[val_copy.index == i] = model_top.predict(val_all_df_x.loc[val_all_df_x.index == i])\n",
    "\n",
    "    return val_copy\n",
    "\n",
    "\n",
    "def mix_results(true_y, pred_y):\n",
    "    \"\"\"\n",
    "    :objective:\n",
    "    :param true_y:\n",
    "    :param pred_y:\n",
    "    :return: plot figure\n",
    "    \"\"\"\n",
    "    # Plot TOP: Predicted vs. True values\n",
    "    plt.figure(figsize=(40, 5))\n",
    "    plt.rcParams[\"axes.grid.axis\"] = \"y\"\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    x = range(0, len(true_y))\n",
    "    plt.plot(x, true_y, label='true', marker='', color='grey', linewidth=2, alpha=0.8)\n",
    "    plt.plot(x, pred_y, label='predicted', marker='', color='tomato', linewidth=2)\n",
    "    pop_b = mpatches.Patch(color='tomato', label='Predicted')\n",
    "    pop_c = mpatches.Patch(color='grey', label='True')\n",
    "    plt.legend(handles=[pop_b, pop_c], fontsize=27, loc=2)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.ylabel('Sales', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "    print(f'MAPE of mixed model is {get_mape(true_y, pred_y)}')\n",
    "    print(f'MAE of mixed model is {get_mae(true_y, pred_y)}')\n",
    "    print(f'RMSE of mixed model is {get_rmse(true_y, pred_y)}')\n",
    "\n",
    "\n",
    "def run_models():\n",
    "    # base model\n",
    "    model_wd_all, preds_wd_all = run_lgbm(params_all_wd, train_wd_lag_x, train_wd_lag_y,\n",
    "                                          val_wd_lag_x, val_wd_lag_y, 'wd_all')\n",
    "    model_wk_all, preds_wk_all = run_lgbm(params_all_wk, train_wk_lag_x, train_wk_lag_y,\n",
    "                                          val_wk_lag_x, val_wk_lag_y, 'wk_all')\n",
    "    # top model\n",
    "    model_wd_top, preds_wd_top = run_lgbm(params_top_wd, top_tr_wd_lag_x, top_tr_wd_lag_y,\n",
    "                                          top_v_wd_lag_x, top_v_wd_lag_y, 'wd_top')\n",
    "    model_wk_top, preds_wk_top = run_lgbm(params_top_wk, top_tr_wk_lag_x, top_tr_wk_lag_y,\n",
    "                                          top_v_wk_lag_x, top_v_wk_lag_y, 'wk_top')\n",
    "    # mixed\n",
    "    mixed_wd = mixed_df(model_wd_top, top_wd_lag, val_wd_lag_x, preds_wd_all, num_top=6017)\n",
    "    mix_results(val_wd_lag_y, mixed_wd[TARGET])\n",
    "    mixed_wk = mixed_df(model_wk_top, top_wk_lag, val_wk_lag_x, preds_wk_all, num_top=3205)\n",
    "    mix_results(val_wk_lag_y, mixed_wk[TARGET])\n",
    "\n",
    "    return mixed_wd, mixed_wk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################################################################\n",
    "######################## Cross Validation ###########################\n",
    "#####################################################################\n",
    "\n",
    "def cross_validation(cv_months=[7, 8, 9]):\n",
    "\n",
    "    # for step 1 model\n",
    "    # wd\n",
    "    for num in cv_months:\n",
    "        month = num\n",
    "        train_x_wd, train_y_wd, val_x_wd, val_y_wd = divide_train_val(df_wd_lag_PP, month, drop=[])\n",
    "        print(f'WD - CV with month {month} is starting.')\n",
    "        run_lgbm(params_all_wd, train_x_wd, train_y_wd, val_x_wd, val_y_wd, 'wd_all')\n",
    "\n",
    "    # wk\n",
    "    for num in cv_months:\n",
    "        month = num\n",
    "        train_x_wk, train_y_wk, val_x_wk, val_y_wk = divide_train_val(df_wk_lag_PP, month, drop=[])\n",
    "        print(f'WK - CV with month {month} is starting.')\n",
    "        run_lgbm(params_all_wk, train_x_wk, train_y_wk, val_x_wk, val_y_wk, 'wk_all')\n",
    "\n",
    "    # for step 3 model\n",
    "    # wd\n",
    "    cv_wd = [[2952, 1052, 12], [4524, 2093, 40]]\n",
    "    for num in cv_months:\n",
    "        print(f'WD - CV for Mixed model - month {num} is starting.')\n",
    "        for lst in cv_wd:\n",
    "            print(f'WD - CV for Mixed model - top {lst[2]}% is starting.')\n",
    "            train = lst[0]\n",
    "            val = lst[1]\n",
    "            train_x_wd_all, train_y_wd_all, val_x_wd_all, val_y_wd_all = divide_train_val(df_wd_lag_PP, num, drop=[])\n",
    "            top_cv, train_x_wd_top, train_y_wd_top, val_x_wd_top, val_y_wd_top = divide_top(df_wd_lag_PP, train, val)\n",
    "            model_all_cv, preds_all_cv = run_lgbm(params_all_wd, train_x_wd_all, train_y_wd_all, val_x_wd_all, val_y_wd_all,\n",
    "                                                  'wd_all')\n",
    "            model_top_cv, preds_top_cv = run_lgbm(params_top_wd, train_x_wd_top, train_y_wd_top, val_x_wd_top, val_y_wd_top,\n",
    "                                                  'wd_top')\n",
    "            mixed_wd = mixed_df(model_top_cv, top_cv, val_x_wd_all, preds_all_cv, num_top=(lst[0] + lst[1]))\n",
    "            mix_results(val_y_wd_all, mixed_wd[TARGET])\n",
    "\n",
    "    # wk\n",
    "    cv_wk = [[1205, 504, 16], [2856, 1359, 40]]\n",
    "    for num in cv_months:\n",
    "        print(f'WK - CV for Mixed model - month {num} is starting.')\n",
    "        for lst in cv_wk:\n",
    "            print(f'WK - CV for Mixed model - top {lst[2]}% is starting.')\n",
    "            train = lst[0]\n",
    "            val = lst[1]\n",
    "            train_x_wk_all, train_y_wk_all, val_x_wk_all, val_y_wk_all = divide_train_val(df_wk_lag_PP, num, drop=[])\n",
    "            top_cv, train_x_wk_top, train_y_wk_top, val_x_wk_top, val_y_wk_top = divide_top(df_wk_lag_PP, train, val)\n",
    "            _, preds_all_cv = run_lgbm(params_all_wk, train_x_wk_all, train_y_wk_all, val_x_wk_all, val_y_wk_all, 'wk_all')\n",
    "            model_top_cv, _ = run_lgbm(params_top_wk, train_x_wk_top, train_y_wk_top, val_x_wk_top, val_y_wk_top, 'wk_top')\n",
    "            mixed_wk = mixed_df(model_top_cv, top_cv, val_x_wk_all, preds_all_cv, num_top=(lst[0] + lst[1]))\n",
    "            mix_results(val_y_wk_all, mixed_wk[TARGET])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################################\n",
    "# #################### Robust Cross Validation ########################\n",
    "# #####################################################################\n",
    "# \"\"\"\n",
    "# perform cross validation on 2019-dec data by 2019 Jan to Aug data\n",
    "# to guarantee the time series robustness of our model\n",
    "# \"\"\"\n",
    "\n",
    "def robust_cross_validation():\n",
    "\n",
    "    # Data preparation, Jan to Aug\n",
    "    train_x_wd_rb, train_y_wd_rb, val_x_wd_rb, val_y_wd_rb = divide_train_val(df_wd_lag_PP, 8, drop=[])\n",
    "    top_wd_rb, top_tr_x_wd_rb, top_tr_y_wd_rb, top_v_x_wd_rb, top_v_y_wd_rb = divide_top(df_wd_lag_PP, 4004, 2013)\n",
    "    train_x_wk_rb, train_y_wk_rb, val_x_wk_rb, val_y_wk_rb = divide_train_val(df_wk_lag_PP, 8, drop=[])\n",
    "    top_wk_rb, top_tr_x_wk_rb, top_tr_y_wk_rb, top_v_x_wk_rb, top_v_y_wk_rb = divide_top(df_wk_lag_PP, 2206, 999)\n",
    "    # target - 2019 Dec\n",
    "    DEC = 12\n",
    "    wd_dec_x = df_wd_lag_PP[df_wd_lag_PP.months == DEC].drop(['index', 'show_id', TARGET], axis=1)\n",
    "    wd_dec_y = df_wd_lag_PP[df_wd_lag_PP.months == DEC][TARGET]\n",
    "    wk_dec_x = df_wk_lag_PP[df_wk_lag_PP.months == DEC].drop(['index', 'show_id', TARGET], axis=1)\n",
    "    wk_dec_y = df_wk_lag_PP[df_wk_lag_PP.months == DEC][TARGET]\n",
    "\n",
    "    # wd\n",
    "    model_all_rb, preds_all_rb = run_lgbm(params_all_wd, train_x_wd_rb, train_y_wd_rb,\n",
    "                                          val_x_wd_rb, val_y_wd_rb, 'wd_all')\n",
    "    model_top_rb, _ = run_lgbm(params_top_wd, top_tr_x_wd_rb, top_tr_y_wd_rb, top_v_x_wd_rb, top_v_y_wd_rb,'wd_top')\n",
    "    preds_wd_dec = model_all_rb.predict(wd_dec_x)\n",
    "    mixed_wd_rb = mixed_df(model_top_rb, top_wd_rb, wd_dec_x, preds_wd_dec, num_top=6017)\n",
    "    mix_results(wd_dec_y, mixed_wd_rb[TARGET])\n",
    "\n",
    "    # wk\n",
    "    model_all_rb, _ = run_lgbm(params_all_wk, train_x_wk_rb, train_y_wk_rb, val_x_wk_rb, val_y_wk_rb, 'wk_all')\n",
    "    model_top_rb, _ = run_lgbm(params_top_wk, top_tr_x_wk_rb, top_tr_y_wk_rb, top_v_x_wk_rb, top_v_y_wk_rb,'wk_top')\n",
    "    preds_wk_dec = model_all_rb.predict(wk_dec_x)\n",
    "    mixed_wk_rb = mixed_df(model_top_rb, top_wk_rb, wk_dec_x, preds_wk_dec, num_top=3205)\n",
    "    mix_results(wk_dec_y, mixed_wk_rb[TARGET])\n",
    "\n",
    "    return mixed_wd_rb, mixed_wk_rb\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
